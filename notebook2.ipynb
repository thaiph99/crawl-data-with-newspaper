{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import numpy as np  \n",
    "import newspaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get urls and keywords from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['https://vnexpress.net/', 'https://www.24h.com.vn/', 'https://tuoitre.vn/']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('urls.txt', 'r') as f:\n",
    "    urls = f.readlines()\n",
    "urls = [url.replace('\\n', '') for url in urls]\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['thủ tướng', 'chính phủ', 'Phạm Minh Chính']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('keywords.txt', 'r') as f:\n",
    "    keywords = f.readlines()\n",
    "keywords = [key.replace('\\n', '') for key in keywords]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['thủ_tướng', 'chính_phủ', 'phạm_minh_chính']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = [key.replace(' ', '_') for key in keywords]\n",
    "keywords = [key.lower() for key in keywords]\n",
    "list_key_tmp = []\n",
    "for key in keywords:\n",
    "    list_key_tmp += key.split('_')\n",
    "\n",
    "# keywords += list_key_tmp\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crawl function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n",
      "https://www.24h.com.vn/bong-da-c48.html\n",
      "https://www.24h.com.vn/kinh-doanh-c161.html\n",
      "https://www.24h.com.vn/thi-truong-tieu-dung-c52.html\n",
      "https://www.24h.com.vn/suc-khoe-doi-song-c62.html\n",
      "https://www.24h.com.vn/thoi-trang-hi-tech-c407.html\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re  \n",
    "\n",
    "def is_valid(url):\n",
    "    # return re.findall(r'\\.[a-z]{3}', url)\n",
    "    return re.findall(r'\\.[a-z]{3}', url) and re.search(r'https://', url)\n",
    "\n",
    "# global dict\n",
    "dict_url = {}\n",
    "\n",
    "def get_link_articles_from_url(url):\n",
    "    respone = requests.get(url)\n",
    "    soup = BeautifulSoup(respone.text, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('a', href=True):\n",
    "        articles_link = a['href'].replace('#box_comment_vne', '')\n",
    "        articles_link = articles_link.replace('#box_comment', '')\n",
    "       \n",
    "        if articles_link not in dict_url.keys() and is_valid(articles_link):\n",
    "            dict_url[articles_link] = 1\n",
    "\n",
    "    return list(dict_url.keys())\n",
    "\n",
    "# test \n",
    "tmp = get_link_articles_from_url(urls[1])\n",
    "print(len(tmp))\n",
    "print(*tmp[:5], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaperedited\n",
    "\n",
    "def get_category(url_home):\n",
    "    dict_cate = {}\n",
    "    home = newspaperedited.build(url_home)\n",
    "    category_urls = home.category_urls()\n",
    "    return list(set(category_urls))\n",
    "\n",
    "list_cate = [get_category(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['https://vnexpress.net/so-hoa',\n 'https://vnexpress.net/giai-tri',\n 'https://vnexpress.net/tin-tuc-24h',\n 'https://vnexpress.net/oto-xe-may',\n 'https://vnexpress.net/du-lich',\n 'https://vnexpress.net/',\n 'https://vnexpress.net',\n 'https://vnexpress.net/thoi-su',\n 'https://vnexpress.net/phap-luat',\n 'https://vnexpress.net/doi-song',\n 'https://vnexpress.net/goc-nhin',\n 'https://vnexpress.net/khoa-hoc',\n 'https://vnexpress.net/hai',\n 'https://vnexpress.net/kinh-doanh',\n 'https://vnexpress.net/the-thao',\n 'https://video.vnexpress.net',\n 'https://vnexpress.net/tam-su',\n 'https://vnexpress.net/the-gioi',\n 'https://vnexpress.net/suc-khoe',\n 'https://vnexpress.net/giao-duc',\n 'https://vnexpress.net/y-kien',\n 'https://e.vnexpress.net',\n 'https://www.24h.com.vn',\n 'https://www.24h.com.vn/',\n 'http://baogia.24h.com.vn',\n 'https://tuoitre.vn/gia-that.htm',\n 'https://tuoitre.vn/media.htm',\n 'https://tuoitre.vn/phap-luat.htm',\n 'https://tuoitre.vn/photo.htm',\n 'https://tuoitre.vn',\n 'https://tuoitre.vn/dien-dan.html',\n 'https://tuoitre.vn/nha-dat.htm',\n 'https://cuoi.tuoitre.vn',\n 'https://tuoitre.vn/',\n 'https://tuyensinh.tuoitre.vn',\n 'https://thethao.tuoitre.vn',\n 'https://dulich.tuoitre.vn',\n 'https://tuoitre.vn/can-biet.htm',\n 'https://tv.tuoitre.vn',\n 'http://id.tuoitre.vn',\n 'https://tuoitre.vn/video.htm',\n 'https://cuoituan.tuoitre.vn',\n 'https://nhadat.tuoitre.vn',\n 'https://tuoitre.vn/xe.htm',\n 'https://tuoitre.vn/van-hoa.htm',\n 'https://tuoitre.vn/thoi-su.htm',\n 'https://tuoitre.vn/khoa-hoc.htm',\n 'https://tuoitre.vn/the-gioi.htm',\n 'https://tuoitre.vn/suc-khoe.htm',\n 'https://tuoitre.vn/the-thao.htm',\n 'https://tuoitre.vn/giao-duc.htm',\n 'http://pay.tuoitre.vn',\n 'https://quangcao.tuoitre.vn',\n 'https://beta.tuoitre.vn',\n 'https://tuoitre.vn/giai-tri.htm',\n 'https://tuoitre.vn/cong-nghe.htm',\n 'https://congnghe.tuoitre.vn',\n 'https://vnexpress.net/',\n 'https://www.24h.com.vn/',\n 'https://tuoitre.vn/']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_categorys = []\n",
    "for i in list_cate:\n",
    "    list_categorys += i  \n",
    "list_categorys += urls\n",
    "list_categorys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get keywords from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_url(url):\n",
    "    text = ''\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "    except:\n",
    "        return text, url\n",
    "    text = article.text.replace('\\n', '.\\n')\n",
    "    url = article.url\n",
    "    return text, url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "def get_keywords_from_text(text):\n",
    "    tokens = ViTokenizer.tokenize(text)\n",
    "    tokens = ViTokenizer.spacy_tokenize(tokens)[0]\n",
    "    tokens = list(filter(lambda x: len(x)>1, tokens))\n",
    "    counter_tokens = Counter(tokens)\n",
    "    counter_tokens = dict(counter_tokens)\n",
    "    counter_tokens = dict(sorted(counter_tokens.items(), key=lambda x:-x[1]))\n",
    "    return counter_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_score(dict_keywords, keys):\n",
    "    score = 0\n",
    "    for key in dict_keywords.keys():\n",
    "        for k in keys:\n",
    "            if k == key.lower():\n",
    "                score += dict_keywords[key]\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranking articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_article_url = []\n",
    "\n",
    "dict_url = {}\n",
    "for category in list_categorys:\n",
    "    list_article_url = get_link_articles_from_url(category)\n",
    "\n",
    "list_article_url = list(set(list_article_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1206"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_article_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = get_text_url(list_article_url[100])\n",
    "# print(list_article_url[100])\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-11-21-31-41-51-61-71-81-91-101-111-121-131-141-151-161-171-181-191-201-211-221-231-241-251-261-271-281-291-301-311-321-331-341-351-361-371-381-391-401-411-421-431-441-451-461-471-481-491-501-511-521-531-541-551-561-571-581-591-601-611-621-631-641-651-661-671-681-691-701-711-721-731-741-751-761-771-781-791-801-811-821-831-841-851-861-871-881-891-901-911-921-931-941-951-961-971-981-991-1001-1011-1021-1031-1041-1051-1061-1071-1081-1091-1101-1111-1121-1131-"
     ]
    }
   ],
   "source": [
    "list_text_url = []\n",
    "cnt = 0\n",
    "for article_url in list_article_url:\n",
    "    text, url = get_text_url(article_url)\n",
    "    if text != '':\n",
    "        list_text_url.append((text, url))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if cnt%10==0:\n",
    "        print(len(list_text_url), end='-')\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136\n"
     ]
    }
   ],
   "source": [
    "print(len(list_text_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_index_and_score = {i:0 for i in range(len(list_text_url))}\n",
    "# dict_index_and_score {0:0, 1:0, 2:0, .....}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-10-20-30-40-50-60-70-80-90-100-110-120-130-140-150-160-170-180-190-200-210-220-230-240-250-260-270-280-290-300-310-320-330-340-350-360-370-380-390-400-410-420-430-440-450-460-470-480-490-500-510-520-530-540-550-560-570-580-590-600-610-620-630-640-650-660-670-680-690-700-710-720-730-740-750-760-770-780-790-800-810-820-830-840-850-860-870-880-890-900-910-920-930-940-950-960-970-980-990-1000-1010-1020-1030-1040-1050-1060-1070-1080-1090-1100-1110-1120-1130-"
     ]
    }
   ],
   "source": [
    "list_keys = []\n",
    "cnt = 0\n",
    "for text, url in list_text_url:\n",
    "    keys = get_keywords_from_text(text)\n",
    "    dict_index_and_score[cnt] = get_important_score(keys, keywords)\n",
    "    if cnt%10==0:\n",
    "        print(cnt, end='-')\n",
    "    cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = dict(sorted(dict_index_and_score.items(), key=lambda x : -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 15\n",
      "https://vnexpress.net/nhung-diem-moi-trong-cac-quyet-dinh-nhan-su-cua-quoc-hoi-4260666.html\n",
      "1087 15\n",
      "https://vnexpress.net/ket-qua-phe-chuan-14-tan-thanh-vien-chinh-phu-4260677.html\n",
      "17 9\n",
      "https://vnexpress.net/chinh-phu-moi-4256811.html\n",
      "376 9\n",
      "https://vnexpress.net/chien-dich-tiem-vaccine-covid-19-cua-thai-lan-bi-chi-trich-4260629.html\n",
      "738 8\n",
      "https://vnexpress.net/tan-bo-truong-nguyen-van-hung-ho-chieu-vaccine-la-chia-khoa-mo-cua-4260489.html\n",
      "191 7\n",
      "https://vnexpress.net/thu-tuong-anh-nhuong-ghe-du-tang-le-hoang-than-philip-4261147.html\n",
      "1091 7\n",
      "https://vnexpress.net/gan-137-trieu-ca-toan-cau-campuchia-nguy-co-vo-tran-covid-19-4261377.html\n",
      "510 5\n",
      "https://vnexpress.net/quyen-luc-mem-cua-chu-tich-nuoc-4259594.html\n",
      "808 5\n",
      "https://vnexpress.net/chinh-phu-huu-hieu-4257910.html\n",
      "465 4\n",
      "https://vnexpress.net/so-ca-covid-19-theo-ngay-o-thai-lan-cao-ky-luc-4261453.html\n",
      "880 4\n",
      "https://www.24h.com.vn/infographics-c765.html\n",
      "43 3\n",
      "https://vnexpress.net/covid-19-tai-chau-a-nong-tro-lai-4260253.html\n",
      "222 3\n",
      "https://vnexpress.net/ho-chieu-vaccine-4258483.html\n",
      "269 3\n",
      "https://vnexpress.net/20-nam-khat-vong-huong-ra-bien-cua-tp-hcm-4260266.html\n",
      "282 3\n",
      "https://vnexpress.net/nhom-hacker-nguy-hiem-tan-cong-mang-chinh-phu-viet-nam-4260247.html\n",
      "426 3\n",
      "https://vnexpress.net/chien-luoc-moi-cua-samsung-san-xuat-da-dia-diem-mua-sam-da-nguon-4260015.html\n",
      "546 3\n",
      "https://vnexpress.net/phe-binh-30-tinh-de-so-nguoi-chet-do-tai-nan-giao-thong-tang-4260471.html\n",
      "677 3\n",
      "https://vnexpress.net/italy-boi-thuong-1-3-trieu-usd-cho-ngu-dan-an-do-bi-ban-chet-4261040.html\n",
      "763 3\n",
      "https://vnexpress.net/gia-vang-the-gioi-len-dinh-mot-thang-4260222.html\n",
      "775 3\n",
      "https://vnexpress.net/thu-tuong-campuchia-doa-bo-tu-nguoi-vi-pham-cach-ly-4261038.html\n"
     ]
    }
   ],
   "source": [
    "cnt = 0 \n",
    "ans = []\n",
    "for i in list_index:\n",
    "    cnt+=1 \n",
    "    print(i, list_index[i])\n",
    "    ans.append(list_text_url[i][1])\n",
    "    print(list_text_url[i][1])\n",
    "    if cnt == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-530c4c780d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtf_idf_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_text_url\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtf_idf_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_text_url\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_idf_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'The TF-IDF vectorizer is not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \"\"\"\n\u001b[1;32m   1248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1250\u001b[0m                 \u001b[0;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \"string object received.\")\n",
      "\u001b[0;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "all_text_tfidf = tfidf_vectorizer.fit_transform(list_text_url[:20][0])\n",
    "\n",
    "list_compare = []\n",
    "\n",
    "for i in range(20):\n",
    "    for j in range(i+1, 20):\n",
    "        tf_idf_i = tfidf_vectorizer.transform(list_text_url[i][0])\n",
    "        tf_idf_j = tfidf_vectorizer.transform(list_text_url[j][0])\n",
    "        dist = cosine_distances(tf_idf_i, tf_idf_j)\n",
    "        list_compare.append((dist, i, j))\n",
    "\n",
    "list_compare = list(sorted(list_compare, key=lambda x: -x[0]))\n",
    "list_compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datacrawled/'\n",
    "cnt = 0\n",
    "dict_title = {}\n",
    "for url in ans:\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "    text = article.text.replace('\\n', '.\\n')\n",
    "    title = article.title\n",
    "    summary = article.summary\n",
    "    url = article.url\n",
    "    if title not in dict_title.keys():\n",
    "        dict_title[title] = 1\n",
    "        cnt += 1\n",
    "        with open(path+'article'+str(cnt)+'.txt', 'w') as f:\n",
    "            f.write(title+'\\n')\n",
    "            f.write(url+'\\n')\n",
    "            f.write(summary+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}