{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import numpy as np  \n",
    "import newspaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get urls and keywords from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['https://vnexpress.net/', 'https://www.24h.com.vn/', 'https://tuoitre.vn/']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('urls.txt', 'r') as f:\n",
    "    urls = f.readlines()\n",
    "urls = [url.replace('\\n', '') for url in urls]\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['thủ tướng', 'chính phủ', 'việt nam', 'Phạm Minh Chính', 'Nhà nước']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('keywords.txt', 'r') as f:\n",
    "    keywords = f.readlines()\n",
    "keywords = [key.replace('\\n', '') for key in keywords]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['thủ_tướng', 'chính_phủ', 'việt_nam', 'phạm_minh_chính', 'nhà_nước']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = [key.replace(' ', '_') for key in keywords]\n",
    "keywords = [key.lower() for key in keywords]\n",
    "list_key_tmp = []\n",
    "for key in keywords:\n",
    "    list_key_tmp += key.split('_')\n",
    "\n",
    "# keywords += list_key_tmp\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crawl function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "https://e.vnexpress.net/\n",
      "https://video.vnexpress.net\n",
      "https://vnexpress.net/trinh-mien-nhiem-13-thanh-vien-chinh-phu-4259027.html\n",
      "https://vnexpress.net/tong-giam-doc-doanh-nghiep-xang-o-sai-gon-bi-bat-4259337.html\n",
      "https://vnexpress.net/hien-truong-ho-tu-than-rong-hon-100-m2-4259284.html\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re  \n",
    "\n",
    "def is_valid(url):\n",
    "    # return re.findall(r'\\.[a-z]{3}', url)\n",
    "    return re.findall(r'\\.[a-z]{3}', url) and re.search(r'https://', url)\n",
    "\n",
    "# global dict\n",
    "dict_url = {}\n",
    "\n",
    "def get_link_articles_from_url(url):\n",
    "    respone = requests.get(url)\n",
    "    soup = BeautifulSoup(respone.text, 'html.parser')\n",
    "    \n",
    "    for a in soup.find_all('a', href=True):\n",
    "        articles_link = a['href'].replace('#box_comment_vne', '')\n",
    "        if articles_link not in dict_url.keys() and is_valid(articles_link):\n",
    "            dict_url[articles_link] = 1\n",
    "\n",
    "    return list(dict_url.keys())\n",
    "\n",
    "# test \n",
    "tmp = get_link_articles_from_url(urls[0])\n",
    "print(len(tmp))\n",
    "print(*tmp[:5], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaperedited\n",
    "\n",
    "def get_category(url_home):\n",
    "    dict_cate = {}\n",
    "    home = newspaperedited.build(url_home)\n",
    "    category_urls = home.category_urls()\n",
    "    return list(set(category_urls))\n",
    "\n",
    "list_cate = [get_category(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['https://vnexpress.net/y-kien',\n 'https://vnexpress.net/suc-khoe',\n 'https://vnexpress.net/doi-song',\n 'https://vnexpress.net/so-hoa',\n 'https://vnexpress.net/the-gioi',\n 'https://vnexpress.net/tin-tuc-24h',\n 'https://vnexpress.net/the-thao',\n 'https://vnexpress.net/kinh-doanh',\n 'https://vnexpress.net/giai-tri',\n 'https://e.vnexpress.net',\n 'https://vnexpress.net/hai',\n 'https://vnexpress.net/thoi-su',\n 'https://video.vnexpress.net',\n 'https://vnexpress.net/khoa-hoc',\n 'https://vnexpress.net/giao-duc',\n 'https://vnexpress.net/goc-nhin',\n 'https://vnexpress.net/phap-luat',\n 'https://vnexpress.net/tam-su',\n 'https://vnexpress.net/du-lich',\n 'https://vnexpress.net/',\n 'https://vnexpress.net',\n 'https://vnexpress.net/oto-xe-may',\n 'https://www.24h.com.vn',\n 'https://www.24h.com.vn/',\n 'http://baogia.24h.com.vn',\n 'https://tuoitre.vn',\n 'https://tuyensinh.tuoitre.vn',\n 'https://tuoitre.vn/phap-luat.htm',\n 'https://dulich.tuoitre.vn',\n 'https://nhadat.tuoitre.vn',\n 'https://quangcao.tuoitre.vn',\n 'https://tuoitre.vn/giao-duc.htm',\n 'https://tuoitre.vn/nha-dat.htm',\n 'http://id.tuoitre.vn',\n 'https://tuoitre.vn/photo.htm',\n 'https://congnghe.tuoitre.vn',\n 'https://tuoitre.vn/thoi-su.htm',\n 'https://cuoi.tuoitre.vn',\n 'https://tuoitre.vn/dien-dan.html',\n 'https://tuoitre.vn/khoa-hoc.htm',\n 'https://tuoitre.vn/can-biet.htm',\n 'https://tuoitre.vn/',\n 'https://tuoitre.vn/suc-khoe.htm',\n 'https://cuoituan.tuoitre.vn',\n 'https://tuoitre.vn/gia-that.htm',\n 'https://tuoitre.vn/giai-tri.htm',\n 'https://tuoitre.vn/the-gioi.htm',\n 'https://thethao.tuoitre.vn',\n 'https://beta.tuoitre.vn',\n 'https://tuoitre.vn/the-thao.htm',\n 'https://tuoitre.vn/xe.htm',\n 'https://tuoitre.vn/van-hoa.htm',\n 'https://tuoitre.vn/video.htm',\n 'https://tv.tuoitre.vn']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_categorys = []\n",
    "for i in list_cate:\n",
    "    list_categorys += i  \n",
    "list_categorys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get keywords from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_url(url):\n",
    "    text = ''\n",
    "    url = ''\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "    except:\n",
    "        return text, url\n",
    "    text = article.text.replace('\\n', '.\\n')\n",
    "    url = article.url\n",
    "    return text, article.url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "def get_keywords_from_text(text):\n",
    "    tokens = ViTokenizer.tokenize(text)\n",
    "    tokens = ViTokenizer.spacy_tokenize(tokens)[0]\n",
    "    tokens = list(filter(lambda x: len(x)>1, tokens))\n",
    "    counter_tokens = Counter(tokens)\n",
    "    counter_tokens = dict(counter_tokens)\n",
    "    counter_tokens = dict(sorted(counter_tokens.items(), key=lambda x:-x[1]))\n",
    "    return counter_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_score(dict_keywords, keys):\n",
    "    score = 0\n",
    "    for key in dict_keywords.keys():\n",
    "        for k in keys:\n",
    "            if k == key.lower():\n",
    "                score += dict_keywords[key]\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranking articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_article_url = []\n",
    "\n",
    "dict_url = {}\n",
    "for category in list_categorys:\n",
    "    list_article_url = get_link_articles_from_url(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1281"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_article_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://vnexpress.net/nhung-buoi-ca-phe-chet-4258591.html\n",
      "('', '')\n"
     ]
    }
   ],
   "source": [
    "t = get_text_url(list_article_url[100])\n",
    "print(list_article_url[100])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_text_url = []\n",
    "cnt = 0\n",
    "for article_url in list_article_url:\n",
    "    text, url = get_text_url(article_url)\n",
    "    if text != '':\n",
    "        list_text_url.append((text, url))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if cnt%10==0:\n",
    "        print(len(list_text_url), end='-')\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(list_text_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_index_and_score = {i:0 for i in range(len(list_text_url))}\n",
    "# dict_index_and_score {0:0, 1:0, 2:0, .....}\n",
    "dict_index_and_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keys = []\n",
    "cnt = 0\n",
    "for text, url in list_text_url:\n",
    "    \n",
    "    keys = get_keywords_from_text(text)\n",
    "    # print(keys)\n",
    "    dict_index_and_score[cnt] = get_important_score(keys, keywords)\n",
    "    if cnt%10==0:\n",
    "        print(cnt, end='-')\n",
    "    cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = dict(sorted(dict_index_and_score.items(), key=lambda x : -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "for i in list_index:\n",
    "    cnt+=1 \n",
    "    print(i, list_index[i])\n",
    "    print(list_text[i][1])\n",
    "    if cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_article_url\n",
    "# print(list_text[557])\n",
    "# tmp1 = get_keywords_from_text(list_text[557])\n",
    "# print(tmp1)\n",
    "# get_important_score(tmp1, ['nhà', 'covid'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}